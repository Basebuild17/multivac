{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk Through for Pure Automated Query Generation\n",
    "This notebook outlines the process of generating novel questions from MULTIVAC's trained query generator based on automated analysis of MULTIVAC's semantic knowledge graph. \n",
    "First, we set up the required imports and arguments for the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multivac.get_kg_query_params import build_network, analyze_network\n",
    "from multivac.src.rdf_graph.map_queries import *\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from multivac.src.gan.gen_test import run\n",
    "os.chdir('src/gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'dir': os.path.abspath('../../data'),\n",
    "             'out': os.path.abspath('../../models'),\n",
    "             'glove': '../../models/glove.42B.300d',\n",
    "             'run': 'model',\n",
    "             'model': 'transe',\n",
    "             'threshold': 0.1,\n",
    "             'num_top_rel': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load up the knowledge graph embedding model previously calculated. This embedding model allows us to assign probabilities to missing nodes or relationships in the knowledge graph proposed via submitted queries. Here we are using TransE, an approach which models relationships by interpreting them as translations operating on the low-dimensional embeddings of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = config.Config()\n",
    "con.set_in_path(args_dict['dir']+os.path.sep)\n",
    "con.set_work_threads(8)\n",
    "con.set_dimension(100)\n",
    "con.set_test_link_prediction(True)\n",
    "con.set_test_triple_classification(True)\n",
    "\n",
    "files = glob.glob(os.path.join(args_dict['out'],'*tf*'))\n",
    "times = list(set([file.split('.')[2] for file in files]))\n",
    "ifile = max([datetime.strptime(x, '%d%b%Y-%H:%M:%S') for x in times]).strftime('%d%b%Y-%H:%M:%S')\n",
    "con.set_import_files(os.path.join(args_dict['out'], 'model.vec.{}.tf'.format(ifile)))\n",
    "\n",
    "con.init()\n",
    "kem = set_model_choice(args_dict['model'])\n",
    "con.set_model(kem)\n",
    "\n",
    "\n",
    "files = [x for x in os.listdir(con.in_path) if '2id' in x]\n",
    "rel_file = sorted([(os.path.getmtime(os.path.join(con.in_path, x)), x)\n",
    "                        for x in files \\\n",
    "                        if 'relation' in  x])\n",
    "rel_file = os.path.join(con.in_path, rel_file[-1][1])\n",
    "\n",
    "ent_file = sorted([(os.path.getmtime(os.path.join(con.in_path, x)), x)\n",
    "                        for x in files \\\n",
    "                        if 'entity' in  x])\n",
    "ent_file = os.path.join(con.in_path, ent_file[-1][1])\n",
    "\n",
    "trn_file = sorted([(os.path.getmtime(os.path.join(con.in_path, x)), x)\n",
    "                        for x in files \\\n",
    "                        if 'train' in  x])\n",
    "trn_file = os.path.join(con.in_path, trn_file[-1][1])\n",
    "\n",
    "entities = pd.read_csv(ent_file, sep='\\t', \n",
    "                       names=[\"Ent\",\"Id\"], skiprows=1)\n",
    "relations = pd.read_csv(rel_file, sep='\\t', \n",
    "                        names=[\"Rel\",\"Id\"], skiprows=1)\n",
    "train = pd.read_csv(trn_file, sep='\\t', \n",
    "                    names=[\"Head\",\"Tail\",\"Relation\"], skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vocab, glove_emb = load_word_vectors(args_dict['glove'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, we let the knowledge graph guide the topic selection and ultimate query generation. We feed the network graph node and edge tuples `networkx` which builds a graph model from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = build_network(train.apply(lambda x: tuple(x), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply graph analytic measures to identify key elements in the graph for exploration. Here for demonstration purposes we use eigenvector centrality, returning the ten nodes with the highest eigenvector centrality values in the knowledge graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_network(network, {'measure': 'eigenvector',\n",
    "                                'num_results': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [x[0] for x in results]\n",
    "key_nodes = entities.Ent[entities.Id.apply(lambda x: x in ids)]\n",
    "\n",
    "key_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we select a seed topic at random from these returns and extract the knowledge graph elements and predicted elements most related to that topic. The system identifies all triples containing the topic or closely semantically related to it, and returns the top num_top_rel results (by default, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_topic = key_nodes.sample().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_object(con, sample_topic, relations, entities, train, glove_vocab, glove_emb, exact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = results.Text.apply(lambda x: run({'query': list(x), \n",
    "                                              'model': os.path.join(args_dict['out'], 'gen_checkpoint.pth')}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
